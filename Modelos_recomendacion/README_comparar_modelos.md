# ğŸ“˜ `comparar_modelos.py` â€” ComparaciÃ³n de modelos clasificadores multiclase

Este script evalÃºa y compara el rendimiento de dos modelos de clasificaciÃ³n multiclase previamente entrenados:

- ğŸ”¹ RegresiÃ³n logÃ­stica multinomial
- ğŸ”¸ Random Forest

---

## ğŸ§  Â¿QuÃ© hace este script?

1. Carga los datos clÃ­nicos desde Excel (`datos_pacientes_entrenamiento.xlsx`)
2. Preprocesa los datos (normalizaciÃ³n, codificaciÃ³n, selecciÃ³n de variables)
3. Aplica un `LabelEncoder` ya entrenado para codificar la variable `farmaco`
4. Divide los datos en entrenamiento y test (20%)
5. Carga los modelos entrenados:
   - `modelo_logistic_reg.pkl`
   - `modelo_random_forest.pkl`
6. Escala los datos solo para el modelo de regresiÃ³n logÃ­stica
7. EvalÃºa ambos modelos:
   - Accuracy
   - F1 Score ponderado
   - Recall promedio
   - Matriz de confusiÃ³n
8. Muestra grÃ¡ficamente las matrices de confusiÃ³n

---

## ğŸ” CaracterÃ­sticas utilizadas

- edad
- IMC_categorica
- genero (0/1)
- Eficacia (normalizada)
- Adherencia
- Gravedad Total
- Todas las columnas que comienzan con `Comorbilidad_` o `EA_`

---

## ğŸ§ª EvaluaciÃ³n

Cada modelo se evalÃºa con las siguientes mÃ©tricas:

- Accuracy global
- F1 Score promedio ponderado
- Recall promedio
- Reporte de clasificaciÃ³n por clase
- Matriz de confusiÃ³n (heatmap con seaborn)

---

## ğŸ¤– Â¿QuÃ© modelos compara?

1. **RegresiÃ³n LogÃ­stica**
   - Entrenado con `StandardScaler`
   - EvalÃºa probabilidades para cada clase
2. **Random Forest**
   - Modelo no paramÃ©trico
   - No requiere escalado
   - Robusto frente a ruido y datos no lineales

---

## ğŸ“‚ Archivos requeridos

- `datos_pacientes_entrenamiento.xlsx`
- `modelo_logistic_reg.pkl`
- `modelo_random_forest.pkl`
- `label_encoder_farmacos.pkl`
- `scaler.pkl`

---

## ğŸ›  Requisitos

```bash
pip install pandas numpy scikit-learn matplotlib seaborn joblib openpyxl
```

---

## â–¶ï¸ EjecuciÃ³n

```bash
python comparar_modelos.py
```

GenerarÃ¡ mÃ©tricas y grÃ¡ficos que te ayudarÃ¡n a elegir el modelo mÃ¡s adecuado para tus predicciones.

